{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af9f520-ee40-40f6-84d9-f7411455f3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Activation, Flatten, Input, LeakyReLU, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.metrics import precision_recall_curve, roc_curve, auc, average_precision_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.stats import ttest_ind\n",
    "from statsmodels.stats.multitest import multipletests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "146bda38-6fa6-4460-a701-30043a21cf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('TCGA_new_pre_second.pckl', 'rb') as file_second:\n",
    "    (dropped_genes_final, dropped_gene_name, dropped_Ens_id, samp_id_new, diag_name_new, project_ids_new) = pd.compat.pickle_compat.load(file_second)\n",
    "with open('TCGA_new_pre_first.pckl', 'rb') as file_first:\n",
    "    _, _, _, _, remain_cancer_ids_ind, remain_normal_ids_ind = pickle.load(file_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dae9bda-e34e-4155-a36e-91cd6d6e8339",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34080</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,362,368</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m2,304\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34080\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │     \u001b[38;5;34m4,362,368\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)             │         \u001b[38;5;34m4,257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,368,929</span> (16.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,368,929\u001b[0m (16.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,368,929</span> (16.67 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,368,929\u001b[0m (16.67 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 103ms/step - categorical_accuracy: 0.2895 - loss: 6.2983 - val_categorical_accuracy: 0.8847 - val_loss: 0.4185\n",
      "Epoch 2/5\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - categorical_accuracy: 0.9077 - loss: 0.3325 - val_categorical_accuracy: 0.9149 - val_loss: 0.2791\n",
      "Epoch 3/5\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - categorical_accuracy: 0.9406 - loss: 0.2037 - val_categorical_accuracy: 0.9338 - val_loss: 0.2087\n",
      "Epoch 4/5\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - categorical_accuracy: 0.9504 - loss: 0.1609 - val_categorical_accuracy: 0.9455 - val_loss: 0.1714\n",
      "Epoch 5/5\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - categorical_accuracy: 0.9587 - loss: 0.1409 - val_categorical_accuracy: 0.9296 - val_loss: 0.2093\n",
      "Categorical Accuracy: 92.96%\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(project_ids_new)\n",
    "onehot_encoder = OneHotEncoder(sparse_output=False)\n",
    "integer_encoded_reshaped = integer_encoded.reshape(-1, 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded_reshaped)\n",
    "X_cancer_samples = dropped_genes_final.iloc[:, remain_cancer_ids_ind].T.values\n",
    "onehot_encoded_cancer_samples = onehot_encoded[remain_cancer_ids_ind]\n",
    "X_cancer_samples_mat = np.concatenate(\n",
    "    (X_cancer_samples, np.zeros((X_cancer_samples.shape[0], 9))),\n",
    "    axis=1\n",
    ")\n",
    "assert X_cancer_samples_mat.shape[1] % (71 * 100) == 0, \"Reshape not possible with current dimensions.\"\n",
    "X_cancer_samples_mat = X_cancer_samples_mat.reshape(-1, 71, 100)\n",
    "num_samples = X_cancer_samples_mat.shape[0]\n",
    "all_indices = np.arange(num_samples)\n",
    "y_labels = integer_encoded[remain_cancer_ids_ind]\n",
    "x_train, x_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "    X_cancer_samples_mat,\n",
    "    onehot_encoded_cancer_samples,\n",
    "    all_indices,\n",
    "    stratify=y_labels,  # Corrected stratify parameter\n",
    "    test_size=0.25,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "img_rows, img_cols = x_test.shape[1], x_test.shape[2]\n",
    "num_classes = y_train.shape[1]\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1).astype('float32')\n",
    "\n",
    "def convolutional_model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=32,\n",
    "            kernel_size=(1, 71),\n",
    "            strides=(1, 1),\n",
    "            input_shape=(img_rows, img_cols, 1)  # Ensure input_shape is correctly set\n",
    "        )\n",
    "    )\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "model = convolutional_model()\n",
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "callbacks = [EarlyStopping(monitor='categorical_accuracy', patience=3, verbose=0)]\n",
    "history = model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=callbacks,validation_data=(x_test, y_test))\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Categorical Accuracy: {scores[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb4666dd-31f0-4832-9775-b9a886195cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">71</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">42</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2982</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,439</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,122</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │            \u001b[38;5;34m18\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m71\u001b[0m, \u001b[38;5;34m42\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2982\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)             │        \u001b[38;5;34m98,439\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m33\u001b[0m)             │         \u001b[38;5;34m1,122\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,579</span> (388.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m99,579\u001b[0m (388.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">99,579</span> (388.98 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m99,579\u001b[0m (388.98 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - categorical_accuracy: 0.0668 - loss: 4.2012 - val_categorical_accuracy: 0.1536 - val_loss: 3.2065\n",
      "Epoch 2/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - categorical_accuracy: 0.1508 - loss: 3.1744 - val_categorical_accuracy: 0.1574 - val_loss: 3.0994\n",
      "Epoch 3/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - categorical_accuracy: 0.1560 - loss: 3.0790 - val_categorical_accuracy: 0.1555 - val_loss: 3.0347\n",
      "Epoch 4/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - categorical_accuracy: 0.1560 - loss: 3.0243 - val_categorical_accuracy: 0.1493 - val_loss: 2.9867\n",
      "Epoch 5/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 31ms/step - categorical_accuracy: 0.1542 - loss: 2.9545 - val_categorical_accuracy: 0.1551 - val_loss: 2.9346\n",
      "Epoch 6/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - categorical_accuracy: 0.1597 - loss: 2.9365 - val_categorical_accuracy: 0.1636 - val_loss: 2.9000\n",
      "Epoch 7/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - categorical_accuracy: 0.1595 - loss: 2.8968 - val_categorical_accuracy: 0.1551 - val_loss: 2.8737\n",
      "Epoch 8/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - categorical_accuracy: 0.1698 - loss: 2.8457 - val_categorical_accuracy: 0.1683 - val_loss: 2.8447\n",
      "Epoch 9/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - categorical_accuracy: 0.1583 - loss: 2.8340 - val_categorical_accuracy: 0.1710 - val_loss: 2.8210\n",
      "Epoch 10/10\n",
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - categorical_accuracy: 0.1623 - loss: 2.7926 - val_categorical_accuracy: 0.1783 - val_loss: 2.7972\n",
      "Categorical Accuracy: 17.83%\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "def small_convolutional_model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Conv2D(\n",
    "            filters=1,\n",
    "            kernel_size= (1, 17),\n",
    "            strides=(1, 1),\n",
    "            input_shape=(img_rows, img_cols, 1)  # Ensure input_shape is correctly set\n",
    "        )\n",
    "    )\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(1, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(33, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "small_model = small_convolutional_model()\n",
    "small_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "small_model.summary()\n",
    "callbacks = [EarlyStopping(monitor='categorical_accuracy', patience=3, verbose=0)]\n",
    "small_history = small_model.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,verbose=1,callbacks=callbacks,validation_data=(x_test, y_test))\n",
    "small_scores = small_model.evaluate(x_test, y_test, verbose=0)\n",
    "print(f\"Categorical Accuracy: {small_scores[1] * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f569cc2-b43e-437c-a155-e758f6601840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected cancer types: ['TCGA-ACC' 'TCGA-BLCA' 'TCGA-BRCA' 'TCGA-CESC' 'TCGA-CHOL' 'TCGA-COAD'\n",
      " 'TCGA-DLBC' 'TCGA-ESCA' 'TCGA-GBM' 'TCGA-HNSC' 'TCGA-KICH' 'TCGA-KIRC'\n",
      " 'TCGA-KIRP' 'TCGA-LGG' 'TCGA-LIHC' 'TCGA-LUAD' 'TCGA-LUSC' 'TCGA-MESO'\n",
      " 'TCGA-OV' 'TCGA-PAAD' 'TCGA-PCPG' 'TCGA-PRAD' 'TCGA-READ' 'TCGA-SARC'\n",
      " 'TCGA-SKCM' 'TCGA-STAD' 'TCGA-TGCT' 'TCGA-THCA' 'TCGA-THYM' 'TCGA-UCEC'\n",
      " 'TCGA-UCS' 'TCGA-UVM' 'TCGA-LAML']\n",
      "\n",
      "Analyzing cancer type: TCGA-ACC (Adrenocortical Carcinoma)\n",
      "Number of samples in TCGA-ACC: 79\n",
      "Number of samples in other cancers: 10261\n",
      "Number of overexpressed genes in TCGA-ACC: 203\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "2917   7965    4.108827    7.408171e-49\n",
      "5514  16712    2.427432    3.689570e-47\n",
      "2737   7470    3.793186    4.874490e-47\n",
      "3797  10602    1.367244    1.636446e-44\n",
      "4916  14171    2.179869    5.001259e-43\n",
      "\n",
      "Analyzing cancer type: TCGA-BLCA (Bladder Urothelial Carcinoma)\n",
      "Number of samples in TCGA-BLCA: 414\n",
      "Number of samples in other cancers: 9926\n",
      "Number of overexpressed genes in TCGA-BLCA: 210\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "2803   7634    1.828840   9.563999e-141\n",
      "3994  11194    1.511596   7.903911e-137\n",
      "3041   8340    1.096399   2.787400e-131\n",
      "685    1780    2.226492   3.503658e-131\n",
      "6710  42114    1.376023   6.596883e-127\n",
      "\n",
      "Analyzing cancer type: TCGA-BRCA (Breast Invasive Carcinoma)\n",
      "Number of samples in TCGA-BRCA: 1108\n",
      "Number of samples in other cancers: 9232\n",
      "Number of overexpressed genes in TCGA-BRCA: 215\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "2700   7386    3.550492             0.0\n",
      "3772  10540    1.606357             0.0\n",
      "3820  10679    1.737072             0.0\n",
      "1283   3419    2.189285             0.0\n",
      "4948  14305    1.035783             0.0\n",
      "\n",
      "Analyzing cancer type: TCGA-CESC (Cervical Squamous Cell Carcinoma and Endocervical Adenocarcinoma)\n",
      "Number of samples in TCGA-CESC: 306\n",
      "Number of samples in other cancers: 10034\n",
      "Number of overexpressed genes in TCGA-CESC: 263\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "4872  13952    1.040641   1.619833e-167\n",
      "3275   9031    1.427807   3.744889e-154\n",
      "2146   5915    1.049848   7.604713e-144\n",
      "2191   6020    1.352469   1.467424e-137\n",
      "5537  16828    1.507637   7.618799e-137\n",
      "\n",
      "Analyzing cancer type: TCGA-CHOL (Cholangiocarcinoma)\n",
      "Number of samples in TCGA-CHOL: 36\n",
      "Number of samples in other cancers: 10304\n",
      "Number of overexpressed genes in TCGA-CHOL: 325\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "1338   3599    1.231842    4.153664e-21\n",
      "4507  12696    3.317805    1.380499e-17\n",
      "2023   5553    1.700450    4.193571e-17\n",
      "2039   5600    1.647529    5.033009e-17\n",
      "4484  12615    1.358913    7.217919e-17\n",
      "\n",
      "Analyzing cancer type: TCGA-COAD (Colon Adenocarcinoma)\n",
      "Number of samples in TCGA-COAD: 478\n",
      "Number of samples in other cancers: 9862\n",
      "Number of overexpressed genes in TCGA-COAD: 405\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "2371   6492    1.523297             0.0\n",
      "5538  16837    1.693314             0.0\n",
      "4139  11625    3.875587             0.0\n",
      "5259  15628    1.321460             0.0\n",
      "5088  14907    2.537678             0.0\n",
      "\n",
      "Analyzing cancer type: TCGA-DLBC (Lymphoid Neoplasm Diffuse Large B-cell Lymphoma)\n",
      "Number of samples in TCGA-DLBC: 48\n",
      "Number of samples in other cancers: 10292\n",
      "Number of overexpressed genes in TCGA-DLBC: 349\n",
      "      Gene  FoldChange  AdjustedPValue\n",
      "3343  9256    1.222871    4.605096e-48\n",
      "2981  8182    1.551369    2.094796e-47\n",
      "1106  2966    1.982446    6.494108e-46\n",
      "1012  2713    1.368795    1.107297e-45\n",
      "145    357    1.434111    3.484668e-45\n",
      "\n",
      "Analyzing cancer type: TCGA-ESCA (Esophageal Carcinoma)\n",
      "Number of samples in TCGA-ESCA: 162\n",
      "Number of samples in other cancers: 10178\n",
      "Number of overexpressed genes in TCGA-ESCA: 358\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "6455  32803    1.643453   5.935024e-121\n",
      "6512  35205    1.567441   6.498639e-100\n",
      "6124  22481    1.733179    5.612204e-87\n",
      "6238  25390    1.282773    6.951734e-83\n",
      "7075  55511    2.434320    7.382219e-81\n",
      "\n",
      "Analyzing cancer type: TCGA-GBM (Glioblastoma Multiforme)\n",
      "Number of samples in TCGA-GBM: 168\n",
      "Number of samples in other cancers: 10172\n",
      "Number of overexpressed genes in TCGA-GBM: 690\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "2335   6398    3.780514   1.409091e-168\n",
      "240     610    2.009045   2.958590e-165\n",
      "2422   6647    1.494777   7.384244e-157\n",
      "5122  15040    2.084802   3.283422e-150\n",
      "2724   7447    2.083783   1.776548e-146\n",
      "\n",
      "Analyzing cancer type: TCGA-HNSC (Head and Neck Squamous Cell Carcinoma)\n",
      "Number of samples in TCGA-HNSC: 502\n",
      "Number of samples in other cancers: 9838\n",
      "Number of overexpressed genes in TCGA-HNSC: 339\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "5426  16331    2.608613             0.0\n",
      "2803   7634    2.297233             0.0\n",
      "4979  14466    2.741741             0.0\n",
      "471    1222    2.389260             0.0\n",
      "4872  13952    1.222017             0.0\n",
      "\n",
      "Analyzing cancer type: TCGA-KICH (Kidney Chromophobe)\n",
      "Number of samples in TCGA-KICH: 65\n",
      "Number of samples in other cancers: 10275\n",
      "Number of overexpressed genes in TCGA-KICH: 332\n",
      "      Gene  FoldChange  AdjustedPValue\n",
      "2062  5674    1.273373    4.235797e-49\n",
      "3262  8999    4.182159    2.782378e-46\n",
      "865   2282    3.925415    2.321468e-45\n",
      "371    948    1.053031    2.675763e-45\n",
      "486   1261    1.485572    3.359747e-44\n",
      "\n",
      "Analyzing cancer type: TCGA-KIRC (Kidney Renal Clear Cell Carcinoma)\n",
      "Number of samples in TCGA-KIRC: 539\n",
      "Number of samples in other cancers: 9801\n",
      "Number of overexpressed genes in TCGA-KIRC: 482\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "2430   6667    2.311917             0.0\n",
      "4604  13011    2.528060             0.0\n",
      "2758   7519    3.475075             0.0\n",
      "5806  17922    2.682527             0.0\n",
      "1380   3709    1.047751             0.0\n",
      "\n",
      "Analyzing cancer type: TCGA-KIRP (Kidney Renal Papillary Cell Carcinoma)\n",
      "Number of samples in TCGA-KIRP: 289\n",
      "Number of samples in other cancers: 10051\n",
      "Number of overexpressed genes in TCGA-KIRP: 418\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "2062   5674    1.748949   1.769303e-249\n",
      "7016  53465    2.358428   2.177606e-224\n",
      "3645  10173    1.781140   2.661146e-205\n",
      "3489   9682    2.606378   4.464195e-201\n",
      "5806  17922    2.560958   5.712764e-189\n",
      "\n",
      "Analyzing cancer type: TCGA-LGG (Brain Lower Grade Glioma)\n",
      "Number of samples in TCGA-LGG: 528\n",
      "Number of samples in other cancers: 9812\n",
      "Number of overexpressed genes in TCGA-LGG: 857\n",
      "      Gene  FoldChange  AdjustedPValue\n",
      "1380  3709    1.256784             0.0\n",
      "3293  9105    1.356519             0.0\n",
      "1604  4333    1.003185             0.0\n",
      "1601  4327    1.281349             0.0\n",
      "1595  4305    3.051615             0.0\n",
      "\n",
      "Analyzing cancer type: TCGA-LIHC (Liver Hepatocellular Carcinoma)\n",
      "Number of samples in TCGA-LIHC: 374\n",
      "Number of samples in other cancers: 9966\n",
      "Number of overexpressed genes in TCGA-LIHC: 391\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "1347   3626    3.963778    0.000000e+00\n",
      "5658  17352    1.397136    0.000000e+00\n",
      "1263   3372    4.240979    0.000000e+00\n",
      "2621   7139    1.880843    0.000000e+00\n",
      "3152   8679    5.269249   1.111348e-314\n",
      "\n",
      "Analyzing cancer type: TCGA-LUAD (Lung Adenocarcinoma)\n",
      "Number of samples in TCGA-LUAD: 535\n",
      "Number of samples in other cancers: 9805\n",
      "Number of overexpressed genes in TCGA-LUAD: 321\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "3633  10132    1.900505   5.333705e-286\n",
      "4421  12453    3.569145   8.729510e-284\n",
      "5584  17031    2.941979   9.047708e-277\n",
      "2667   7264    3.291399   3.123514e-272\n",
      "649    1697    1.717006   3.142767e-272\n",
      "\n",
      "Analyzing cancer type: TCGA-LUSC (Lung Squamous Cell Carcinoma)\n",
      "Number of samples in TCGA-LUSC: 502\n",
      "Number of samples in other cancers: 9838\n",
      "Number of overexpressed genes in TCGA-LUSC: 388\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "5944  20168    2.211879   3.692099e-237\n",
      "5393  16142    1.798745   7.713329e-220\n",
      "471    1222    2.257780   1.205375e-214\n",
      "2803   7634    2.134158   1.745997e-213\n",
      "2754   7509    1.439457   6.490748e-210\n",
      "\n",
      "Analyzing cancer type: TCGA-MESO (Mesothelioma)\n",
      "Number of samples in TCGA-MESO: 86\n",
      "Number of samples in other cancers: 10254\n",
      "Number of overexpressed genes in TCGA-MESO: 225\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "1638   4418    1.235065    4.658068e-49\n",
      "2198   6040    1.504858    5.346289e-47\n",
      "2004   5481    2.008840    1.521043e-42\n",
      "2039   5600    1.737479    4.624975e-42\n",
      "4728  13405    1.564299    1.217370e-41\n",
      "\n",
      "Analyzing cancer type: TCGA-OV (Ovarian Serous Cystadenocarcinoma)\n",
      "Number of samples in TCGA-OV: 379\n",
      "Number of samples in other cancers: 9961\n",
      "Number of overexpressed genes in TCGA-OV: 367\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "4119  11552    1.106451    0.000000e+00\n",
      "4073  11424    2.216639   2.960441e-320\n",
      "6378  30146    1.330118   1.120507e-276\n",
      "1010   2708    1.960513   6.210327e-274\n",
      "6435  32314    1.279913   4.152643e-272\n",
      "\n",
      "Analyzing cancer type: TCGA-PAAD (Pancreatic Adenocarcinoma)\n",
      "Number of samples in TCGA-PAAD: 178\n",
      "Number of samples in other cancers: 10162\n",
      "Number of overexpressed genes in TCGA-PAAD: 346\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "4507  12696    3.006318    2.891490e-85\n",
      "2140   5900    1.696379    1.018621e-80\n",
      "2956   8109    1.113763    3.596096e-80\n",
      "2039   5600    1.431761    1.706931e-79\n",
      "4032  11301    2.146313    3.045867e-79\n",
      "\n",
      "Analyzing cancer type: TCGA-PCPG (Pheochromocytoma and Paraganglioma)\n",
      "Number of samples in TCGA-PCPG: 183\n",
      "Number of samples in other cancers: 10157\n",
      "Number of overexpressed genes in TCGA-PCPG: 515\n",
      "      Gene  FoldChange  AdjustedPValue\n",
      "2455  6730    2.270906   1.028983e-268\n",
      "925   2470    1.797138   2.801726e-262\n",
      "885   2354    3.801956   4.771449e-207\n",
      "2484  6802    3.245986   2.044946e-192\n",
      "972   2607    2.893660   1.071456e-190\n",
      "\n",
      "Analyzing cancer type: TCGA-PRAD (Prostate Adenocarcinoma)\n",
      "Number of samples in TCGA-PRAD: 499\n",
      "Number of samples in other cancers: 9841\n",
      "Number of overexpressed genes in TCGA-PRAD: 422\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "2241   6148    1.751159             0.0\n",
      "5538  16837    1.809049             0.0\n",
      "1435   3846    1.071943             0.0\n",
      "3695  10305    3.196125             0.0\n",
      "3742  10435    1.423262             0.0\n",
      "\n",
      "Analyzing cancer type: TCGA-READ (Rectum Adenocarcinoma)\n",
      "Number of samples in TCGA-READ: 166\n",
      "Number of samples in other cancers: 10174\n",
      "Number of overexpressed genes in TCGA-READ: 388\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "4645  13126    2.468917   1.183574e-183\n",
      "4886  14013    1.680440   1.184631e-181\n",
      "1152   3094    2.235311   2.592823e-175\n",
      "4773  13564    2.473586   4.950704e-173\n",
      "811    2116    1.390630   1.951448e-165\n",
      "\n",
      "Analyzing cancer type: TCGA-SARC (Sarcoma)\n",
      "Number of samples in TCGA-SARC: 263\n",
      "Number of samples in other cancers: 10077\n",
      "Number of overexpressed genes in TCGA-SARC: 149\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "1826   4968    1.035579   2.425955e-130\n",
      "3863  10811    1.192726   2.862165e-117\n",
      "5228  15511    1.118317   3.074275e-117\n",
      "1891   5148    1.088317    5.991905e-94\n",
      "5075  14862    1.158471    8.019221e-87\n",
      "\n",
      "Analyzing cancer type: TCGA-SKCM (Skin Cutaneous Melanoma)\n",
      "Number of samples in TCGA-SKCM: 471\n",
      "Number of samples in other cancers: 9869\n",
      "Number of overexpressed genes in TCGA-SKCM: 188\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "6603  37213    1.109564   6.674734e-271\n",
      "1875   5106    1.297351   1.460747e-258\n",
      "1980   5397    2.727751   5.423550e-257\n",
      "5373  16037    2.017051   3.343784e-245\n",
      "3748  10468    1.946137   1.569132e-235\n",
      "\n",
      "Analyzing cancer type: TCGA-STAD (Stomach Adenocarcinoma)\n",
      "Number of samples in TCGA-STAD: 374\n",
      "Number of samples in other cancers: 9966\n",
      "Number of overexpressed genes in TCGA-STAD: 407\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "4886  14013    1.503018   8.120811e-213\n",
      "6512  35205    1.683145   3.514586e-203\n",
      "5779  17842    2.488677   2.354383e-194\n",
      "6146  22759    1.014618   2.437732e-190\n",
      "811    2116    1.204487   2.116499e-187\n",
      "\n",
      "Analyzing cancer type: TCGA-TGCT (Testicular Germ Cell Tumors)\n",
      "Number of samples in TCGA-TGCT: 142\n",
      "Number of samples in other cancers: 10198\n",
      "Number of overexpressed genes in TCGA-TGCT: 296\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "5302  15788    3.467245    3.422434e-81\n",
      "2515   6882    2.202683    2.982293e-70\n",
      "4220  11883    1.012517    1.057332e-65\n",
      "4786  13597    1.315264    6.425006e-64\n",
      "4949  14307    2.393158    1.410744e-63\n",
      "\n",
      "Analyzing cancer type: TCGA-THCA (Thyroid Carcinoma)\n",
      "Number of samples in TCGA-THCA: 508\n",
      "Number of samples in other cancers: 9832\n",
      "Number of overexpressed genes in TCGA-THCA: 319\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "4624  13062    1.466979             0.0\n",
      "2453   6726    1.207332             0.0\n",
      "2392   6562    2.026236             0.0\n",
      "5771  17825    1.344958             0.0\n",
      "2062   5674    2.104987             0.0\n",
      "\n",
      "Analyzing cancer type: TCGA-THYM (Thymoma)\n",
      "Number of samples in TCGA-THYM: 119\n",
      "Number of samples in other cancers: 10221\n",
      "Number of overexpressed genes in TCGA-THYM: 370\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "5393  16142    1.609212   2.465605e-100\n",
      "1351   3632    3.452584    7.680555e-91\n",
      "1827   4969    1.606001    2.726975e-87\n",
      "3016   8279    1.031775    4.596237e-80\n",
      "4979  14466    2.656778    4.542945e-78\n",
      "\n",
      "Analyzing cancer type: TCGA-UCEC (Uterine Corpus Endometrial Carcinoma)\n",
      "Number of samples in TCGA-UCEC: 552\n",
      "Number of samples in other cancers: 9788\n",
      "Number of overexpressed genes in TCGA-UCEC: 237\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "5373  16037    1.859883    0.000000e+00\n",
      "4073  11424    2.324317   1.092170e-299\n",
      "2062   5674    1.768819   4.445983e-289\n",
      "947    2530    1.254270   2.657081e-275\n",
      "2312   6337    1.020963   1.679596e-266\n",
      "\n",
      "Analyzing cancer type: TCGA-UCS (Uterine Carcinosarcoma)\n",
      "Number of samples in TCGA-UCS: 56\n",
      "Number of samples in other cancers: 10284\n",
      "Number of overexpressed genes in TCGA-UCS: 298\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "5373  16037    1.722735    2.257067e-33\n",
      "6715  42263    1.243325    3.684529e-32\n",
      "5071  14839    1.278372    8.664000e-31\n",
      "3513   9748    1.116330    5.708780e-29\n",
      "1127   3042    1.070187    4.035964e-27\n",
      "\n",
      "Analyzing cancer type: TCGA-UVM (Uveal Melanoma)\n",
      "Number of samples in TCGA-UVM: 80\n",
      "Number of samples in other cancers: 10260\n",
      "Number of overexpressed genes in TCGA-UVM: 207\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "1849   5019    4.120725   2.610333e-107\n",
      "1655   4463    1.379960    1.259614e-98\n",
      "1988   5428    1.647707    5.641821e-95\n",
      "4934  14270    2.762271    1.736625e-92\n",
      "2528   6913    1.625288    4.021057e-88\n",
      "\n",
      "Analyzing cancer type: TCGA-LAML (Acute Myeloid Leukemia)\n",
      "Number of samples in TCGA-LAML: 151\n",
      "Number of samples in other cancers: 10189\n",
      "Number of overexpressed genes in TCGA-LAML: 532\n",
      "       Gene  FoldChange  AdjustedPValue\n",
      "4427  12467    1.511611   3.710896e-178\n",
      "1965   5367    1.766466   8.327916e-167\n",
      "5376  16065    2.144174   5.177534e-166\n",
      "247     648    1.421698   3.344235e-164\n",
      "1665   4506    1.419510   6.666661e-153\n"
     ]
    }
   ],
   "source": [
    "gene_expression = dropped_genes_final.iloc[:, remain_cancer_ids_ind].T  # Now rows are samples, columns are genes\n",
    "gene_expression.index = samp_id_new[remain_cancer_ids_ind]  # Assign sample IDs as index\n",
    "labels = pd.Series(project_ids_new[remain_cancer_ids_ind], index=gene_expression.index)\n",
    "label_names = pd.Series(diag_name_new[remain_cancer_ids_ind], index=gene_expression.index)\n",
    "cancer_types = labels.unique()\n",
    "print(f\"Detected cancer types: {cancer_types}\")\n",
    "overexpressed_genes = {}\n",
    "\n",
    "for cancer in cancer_types:\n",
    "    print(f\"\\nAnalyzing cancer type: {cancer} ({label_names[labels == cancer].iloc[0]})\")\n",
    "    binary_labels = (labels == cancer).astype(int)\n",
    "    expr_cancer = gene_expression[binary_labels == 1]\n",
    "    expr_other = gene_expression[binary_labels == 0]\n",
    "    print(f\"Number of samples in {cancer}: {expr_cancer.shape[0]}\")\n",
    "    print(f\"Number of samples in other cancers: {expr_other.shape[0]}\")\n",
    "    p_values = []\n",
    "    fold_changes = []\n",
    "\n",
    "    for gene in gene_expression.columns:\n",
    "        expr1 = expr_cancer[gene]\n",
    "        expr2 = expr_other[gene]\n",
    "        t_stat, p_val = ttest_ind(expr1, expr2, equal_var=False)  # Welch's t-test\n",
    "        p_values.append(p_val)\n",
    "        mean_cancer = expr1.mean()\n",
    "        mean_other = expr2.mean()\n",
    "        fold_change = np.log2((mean_cancer + 1e-9) / (mean_other + 1e-9))\n",
    "        fold_changes.append(fold_change)\n",
    "    p_values = np.array(p_values)\n",
    "    reject, pvals_corrected, _, _ = multipletests(p_values, alpha=0.05, method='fdr_bh')\n",
    "\n",
    "    results = pd.DataFrame({\n",
    "        'Gene': gene_expression.columns,\n",
    "        'FoldChange': fold_changes,\n",
    "        'PValue': p_values,\n",
    "        'AdjustedPValue': pvals_corrected,\n",
    "        'Significant': reject\n",
    "    })\n",
    "    overexpressed = results[(results['FoldChange'] > 1) & (results['Significant'])]\n",
    "    overexpressed = overexpressed.sort_values('AdjustedPValue')\n",
    "    top_n = 50\n",
    "    overexpressed_genes[cancer] = overexpressed.head(top_n)\n",
    "    print(f\"Number of overexpressed genes in {cancer}: {overexpressed.shape[0]}\")\n",
    "    print(overexpressed[['Gene', 'FoldChange', 'AdjustedPValue']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23a7df21-f31f-4cb6-b5f5-80d6fd4d0972",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(128)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e134c3f6-ad01-4321-a22c-ca81c6e9dfc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/50\n",
      "Batch 0: Total Loss: 9.975980758666992, Student Loss: 4.583693504333496, Attention Loss: 5.392286777496338\n",
      "Epoch 1, Test Loss: 2.2423, Test Accuracy: 32.52%\n",
      "Starting epoch 2/50\n",
      "Batch 0: Total Loss: 7.703660011291504, Student Loss: 2.3114302158355713, Attention Loss: 5.392230033874512\n",
      "Epoch 2, Test Loss: 1.6114, Test Accuracy: 53.51%\n",
      "Starting epoch 3/50\n",
      "Batch 0: Total Loss: 7.068301200866699, Student Loss: 1.6776411533355713, Attention Loss: 5.390660285949707\n",
      "Epoch 3, Test Loss: 1.2205, Test Accuracy: 63.98%\n",
      "Starting epoch 4/50\n",
      "Batch 0: Total Loss: 6.7302446365356445, Student Loss: 1.3399850130081177, Attention Loss: 5.390259742736816\n",
      "Epoch 4, Test Loss: 0.9653, Test Accuracy: 70.91%\n",
      "Starting epoch 5/50\n",
      "Batch 0: Total Loss: 6.479156970977783, Student Loss: 1.0907769203186035, Attention Loss: 5.38838005065918\n",
      "Epoch 5, Test Loss: 0.8355, Test Accuracy: 73.41%\n",
      "Starting epoch 6/50\n",
      "Batch 0: Total Loss: 6.341330051422119, Student Loss: 0.9541469812393188, Attention Loss: 5.38718318939209\n",
      "Epoch 6, Test Loss: 0.7440, Test Accuracy: 74.97%\n",
      "Starting epoch 7/50\n",
      "Batch 0: Total Loss: 6.2516374588012695, Student Loss: 0.8651292324066162, Attention Loss: 5.386507987976074\n",
      "Epoch 7, Test Loss: 0.6736, Test Accuracy: 78.44%\n",
      "Starting epoch 8/50\n",
      "Batch 0: Total Loss: 6.176424980163574, Student Loss: 0.7908647060394287, Attention Loss: 5.385560035705566\n",
      "Epoch 8, Test Loss: 0.6063, Test Accuracy: 81.98%\n",
      "Starting epoch 9/50\n",
      "Batch 0: Total Loss: 6.09239387512207, Student Loss: 0.7079226970672607, Attention Loss: 5.384471416473389\n",
      "Epoch 9, Test Loss: 0.5686, Test Accuracy: 82.83%\n",
      "Starting epoch 10/50\n",
      "Batch 0: Total Loss: 6.0512871742248535, Student Loss: 0.6676455736160278, Attention Loss: 5.383641719818115\n",
      "Epoch 10, Test Loss: 0.5179, Test Accuracy: 84.95%\n",
      "Starting epoch 11/50\n",
      "Batch 0: Total Loss: 6.002362251281738, Student Loss: 0.6195013523101807, Attention Loss: 5.382861137390137\n",
      "Epoch 11, Test Loss: 0.4809, Test Accuracy: 86.06%\n",
      "Starting epoch 12/50\n",
      "Batch 0: Total Loss: 5.973988056182861, Student Loss: 0.5919271111488342, Attention Loss: 5.382061004638672\n",
      "Epoch 12, Test Loss: 0.4599, Test Accuracy: 86.73%\n",
      "Starting epoch 13/50\n",
      "Batch 0: Total Loss: 5.956003189086914, Student Loss: 0.5744990110397339, Attention Loss: 5.381504058837891\n",
      "Epoch 13, Test Loss: 0.4460, Test Accuracy: 86.96%\n",
      "Starting epoch 14/50\n",
      "Batch 0: Total Loss: 5.9394330978393555, Student Loss: 0.5586539506912231, Attention Loss: 5.380779266357422\n",
      "Epoch 14, Test Loss: 0.4322, Test Accuracy: 87.74%\n",
      "Starting epoch 15/50\n",
      "Batch 0: Total Loss: 5.915111541748047, Student Loss: 0.5351486802101135, Attention Loss: 5.379962921142578\n",
      "Epoch 15, Test Loss: 0.4235, Test Accuracy: 88.15%\n",
      "Starting epoch 16/50\n",
      "Batch 0: Total Loss: 5.896059513092041, Student Loss: 0.5168502926826477, Attention Loss: 5.379209041595459\n",
      "Epoch 16, Test Loss: 0.4145, Test Accuracy: 88.38%\n",
      "Starting epoch 17/50\n",
      "Batch 0: Total Loss: 5.8740949630737305, Student Loss: 0.49600040912628174, Attention Loss: 5.378094673156738\n",
      "Epoch 17, Test Loss: 0.4066, Test Accuracy: 88.52%\n",
      "Starting epoch 18/50\n",
      "Batch 0: Total Loss: 5.852664947509766, Student Loss: 0.4756293296813965, Attention Loss: 5.377035617828369\n",
      "Epoch 18, Test Loss: 0.3995, Test Accuracy: 88.75%\n",
      "Starting epoch 19/50\n",
      "Batch 0: Total Loss: 5.830758571624756, Student Loss: 0.4548295736312866, Attention Loss: 5.37592887878418\n",
      "Epoch 19, Test Loss: 0.3946, Test Accuracy: 88.90%\n",
      "Starting epoch 20/50\n",
      "Batch 0: Total Loss: 5.812169075012207, Student Loss: 0.4374261200428009, Attention Loss: 5.3747429847717285\n",
      "Epoch 20, Test Loss: 0.3922, Test Accuracy: 88.79%\n",
      "Starting epoch 21/50\n",
      "Batch 0: Total Loss: 5.797365188598633, Student Loss: 0.42358601093292236, Attention Loss: 5.373779296875\n",
      "Epoch 21, Test Loss: 0.3947, Test Accuracy: 88.75%\n",
      "Starting epoch 22/50\n",
      "Batch 0: Total Loss: 5.790008068084717, Student Loss: 0.4168850779533386, Attention Loss: 5.3731231689453125\n",
      "Epoch 22, Test Loss: 0.3974, Test Accuracy: 88.45%\n",
      "Starting epoch 23/50\n",
      "Batch 0: Total Loss: 5.778620719909668, Student Loss: 0.40630319714546204, Attention Loss: 5.372317314147949\n",
      "Epoch 23, Test Loss: 0.4012, Test Accuracy: 88.19%\n",
      "Starting epoch 24/50\n",
      "Batch 0: Total Loss: 5.766628742218018, Student Loss: 0.3948608636856079, Attention Loss: 5.371767997741699\n",
      "Epoch 24, Test Loss: 0.4030, Test Accuracy: 87.44%\n",
      "Starting epoch 25/50\n",
      "Batch 0: Total Loss: 5.750281810760498, Student Loss: 0.3793908357620239, Attention Loss: 5.370891094207764\n",
      "Epoch 25, Test Loss: 0.3974, Test Accuracy: 87.67%\n",
      "Starting epoch 26/50\n",
      "Batch 0: Total Loss: 5.7301788330078125, Student Loss: 0.35996365547180176, Attention Loss: 5.37021541595459\n",
      "Epoch 26, Test Loss: 0.3887, Test Accuracy: 87.67%\n",
      "Starting epoch 27/50\n",
      "Batch 0: Total Loss: 5.719283103942871, Student Loss: 0.34782901406288147, Attention Loss: 5.371454238891602\n",
      "Epoch 27, Test Loss: 0.4019, Test Accuracy: 87.18%\n",
      "Starting epoch 28/50\n",
      "Batch 0: Total Loss: 5.732065200805664, Student Loss: 0.35916489362716675, Attention Loss: 5.372900485992432\n",
      "Epoch 28, Test Loss: 0.3967, Test Accuracy: 87.30%\n",
      "Starting epoch 29/50\n",
      "Batch 0: Total Loss: 5.721479892730713, Student Loss: 0.34889286756515503, Attention Loss: 5.372587203979492\n",
      "Epoch 29, Test Loss: 0.3687, Test Accuracy: 88.78%\n",
      "Starting epoch 30/50\n",
      "Batch 0: Total Loss: 5.7001423835754395, Student Loss: 0.32966887950897217, Attention Loss: 5.370473384857178\n",
      "Epoch 30, Test Loss: 0.3624, Test Accuracy: 89.35%\n",
      "Starting epoch 31/50\n",
      "Batch 0: Total Loss: 5.690185546875, Student Loss: 0.3206241726875305, Attention Loss: 5.369561195373535\n",
      "Epoch 31, Test Loss: 0.3589, Test Accuracy: 89.38%\n",
      "Starting epoch 32/50\n",
      "Batch 0: Total Loss: 5.6822967529296875, Student Loss: 0.313332736492157, Attention Loss: 5.368964195251465\n",
      "Epoch 32, Test Loss: 0.3577, Test Accuracy: 89.83%\n",
      "Starting epoch 33/50\n",
      "Batch 0: Total Loss: 5.677778720855713, Student Loss: 0.30914080142974854, Attention Loss: 5.368638038635254\n",
      "Epoch 33, Test Loss: 0.3587, Test Accuracy: 89.83%\n",
      "Starting epoch 34/50\n",
      "Batch 0: Total Loss: 5.677053451538086, Student Loss: 0.30834224820137024, Attention Loss: 5.368710994720459\n",
      "Epoch 34, Test Loss: 0.3673, Test Accuracy: 89.83%\n",
      "Starting epoch 35/50\n",
      "Batch 0: Total Loss: 5.6858296394348145, Student Loss: 0.31628355383872986, Attention Loss: 5.369545936584473\n",
      "Epoch 35, Test Loss: 0.3804, Test Accuracy: 89.83%\n",
      "Starting epoch 36/50\n",
      "Batch 0: Total Loss: 5.694944381713867, Student Loss: 0.3248300552368164, Attention Loss: 5.370114326477051\n",
      "Epoch 36, Test Loss: 0.3742, Test Accuracy: 90.01%\n",
      "Starting epoch 37/50\n",
      "Batch 0: Total Loss: 5.662545204162598, Student Loss: 0.29377827048301697, Attention Loss: 5.368766784667969\n",
      "Epoch 37, Test Loss: 0.3643, Test Accuracy: 90.05%\n",
      "Starting epoch 38/50\n",
      "Batch 0: Total Loss: 5.632723331451416, Student Loss: 0.2658138573169708, Attention Loss: 5.366909503936768\n",
      "Epoch 38, Test Loss: 0.3598, Test Accuracy: 90.16%\n",
      "Starting epoch 39/50\n",
      "Batch 0: Total Loss: 5.613877773284912, Student Loss: 0.24791759252548218, Attention Loss: 5.365960121154785\n",
      "Epoch 39, Test Loss: 0.3580, Test Accuracy: 89.86%\n",
      "Starting epoch 40/50\n",
      "Batch 0: Total Loss: 5.597660541534424, Student Loss: 0.23261287808418274, Attention Loss: 5.365047454833984\n",
      "Epoch 40, Test Loss: 0.3582, Test Accuracy: 89.94%\n",
      "Starting epoch 41/50\n",
      "Batch 0: Total Loss: 5.586082935333252, Student Loss: 0.22173452377319336, Attention Loss: 5.364348411560059\n",
      "Epoch 41, Test Loss: 0.3565, Test Accuracy: 90.13%\n",
      "Starting epoch 42/50\n",
      "Batch 0: Total Loss: 5.571657180786133, Student Loss: 0.20842930674552917, Attention Loss: 5.363227844238281\n",
      "Epoch 42, Test Loss: 0.3569, Test Accuracy: 90.02%\n",
      "Starting epoch 43/50\n",
      "Batch 0: Total Loss: 5.561159610748291, Student Loss: 0.19925814867019653, Attention Loss: 5.36190128326416\n",
      "Epoch 43, Test Loss: 0.3604, Test Accuracy: 90.02%\n",
      "Starting epoch 44/50\n",
      "Batch 0: Total Loss: 5.552464485168457, Student Loss: 0.1911669373512268, Attention Loss: 5.361297607421875\n",
      "Epoch 44, Test Loss: 0.3638, Test Accuracy: 89.53%\n",
      "Starting epoch 45/50\n",
      "Batch 0: Total Loss: 5.546161651611328, Student Loss: 0.18581244349479675, Attention Loss: 5.360349178314209\n",
      "Epoch 45, Test Loss: 0.3671, Test Accuracy: 89.19%\n",
      "Starting epoch 46/50\n",
      "Batch 0: Total Loss: 5.536159038543701, Student Loss: 0.1769062876701355, Attention Loss: 5.3592529296875\n",
      "Epoch 46, Test Loss: 0.3739, Test Accuracy: 89.11%\n",
      "Starting epoch 47/50\n",
      "Batch 0: Total Loss: 5.536491870880127, Student Loss: 0.1775425374507904, Attention Loss: 5.358949184417725\n",
      "Epoch 47, Test Loss: 0.3760, Test Accuracy: 89.15%\n",
      "Starting epoch 48/50\n",
      "Batch 0: Total Loss: 5.526561260223389, Student Loss: 0.1691506952047348, Attention Loss: 5.357410430908203\n",
      "Epoch 48, Test Loss: 0.3887, Test Accuracy: 89.00%\n",
      "Starting epoch 49/50\n",
      "Batch 0: Total Loss: 5.523319244384766, Student Loss: 0.16579128801822662, Attention Loss: 5.357527732849121\n",
      "Epoch 49, Test Loss: 0.4000, Test Accuracy: 88.67%\n",
      "Starting epoch 50/50\n",
      "Batch 0: Total Loss: 5.527458190917969, Student Loss: 0.17142941057682037, Attention Loss: 5.3560285568237305\n",
      "Epoch 50, Test Loss: 0.4087, Test Accuracy: 88.52%\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "genes_list = dropped_genes_final\n",
    "num_genes = len(genes_list)\n",
    "grid_size = (71, 100)\n",
    "if num_genes > grid_size[0] * grid_size[1]:\n",
    "    raise ValueError(\"Number of genes exceeds the grid size.\")\n",
    "\n",
    "gene_to_pos_map = {}\n",
    "idx = 0\n",
    "\n",
    "for gene in dropped_genes_final.index:\n",
    "    row = idx // grid_size[1]\n",
    "    col = idx % grid_size[1]\n",
    "    gene_to_pos_map[gene] = (row, col)\n",
    "    idx += 1\n",
    "\n",
    "def create_saliency_map(sample_cancer_type, gene_to_pos_map, overexpressed_genes, grid_size=(71, 100)):\n",
    "    saliency_map = np.zeros(grid_size, dtype=np.float32)\n",
    "    genes_df = overexpressed_genes.get(sample_cancer_type)\n",
    "    if genes_df is not None:\n",
    "        for gene, fold_change in zip(genes_df['Gene'], genes_df['FoldChange']):\n",
    "            pos = gene_to_pos_map.get(gene)\n",
    "            if pos:\n",
    "                row, col = pos\n",
    "                saliency_map[row, col] = fold_change\n",
    "    saliency_map = np.expand_dims(saliency_map, axis=-1)\n",
    "    return saliency_map\n",
    "\n",
    "y_labels_train = labels.iloc[train_indices].values\n",
    "teacher_saliency_train = np.array([\n",
    "    create_saliency_map(cancer_type, gene_to_pos_map, overexpressed_genes)\n",
    "    for cancer_type in y_labels_train\n",
    "])\n",
    "BATCH_SIZE = 128  \n",
    "saliency_dataset = tf.data.Dataset.from_tensor_slices(teacher_saliency_train).batch(BATCH_SIZE)\n",
    "train_dataset_with_saliency = tf.data.Dataset.zip((train_dataset, saliency_dataset))\n",
    "\n",
    "conv_model2 = small_convolutional_model()\n",
    "conv_model2.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['categorical_accuracy']\n",
    ")\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "@tf.function\n",
    "def attention_transfer_loss_top10_euclidean_distance_both(teacher_saliency_map, student_saliency_map):\n",
    "    teacher_saliency_map = tf.cast(teacher_saliency_map, tf.float32)\n",
    "    student_saliency_map = tf.cast(student_saliency_map, tf.float32)\n",
    "    batch_size = tf.shape(teacher_saliency_map)[0]\n",
    "    teacher_flat = tf.reshape(teacher_saliency_map, [batch_size, -1])\n",
    "    student_flat = tf.reshape(student_saliency_map, [batch_size, -1])\n",
    "    num_pixels = tf.shape(teacher_flat)[1]\n",
    "    num_top_values = tf.cast(0.1 * tf.cast(num_pixels, tf.float32), tf.int32)\n",
    "    num_bottom_values = tf.cast(0.02 * tf.cast(num_pixels, tf.float32), tf.int32)\n",
    "    top_values, _ = tf.math.top_k(teacher_flat, k=num_top_values, sorted=True)\n",
    "    bottom_values, _ = tf.math.top_k(-teacher_flat, k=num_bottom_values, sorted=True)\n",
    "    bottom_values = -bottom_values\n",
    "    sorted_indices = tf.argsort(teacher_flat, axis=1, direction='ASCENDING')\n",
    "    top_indices = sorted_indices[:, -num_top_values:]\n",
    "    bottom_indices = sorted_indices[:, :num_bottom_values]\n",
    "    batch_indices = tf.reshape(tf.range(batch_size), [-1, 1])\n",
    "    batch_indices = tf.tile(batch_indices, [1, num_top_values])\n",
    "    top_gather_indices = tf.stack([tf.cast(batch_indices, tf.int32), tf.cast(top_indices, tf.int32)], axis=-1)\n",
    "    student_top_values = tf.gather_nd(student_flat, top_gather_indices)\n",
    "    batch_indices_bottom = tf.reshape(tf.range(batch_size), [-1, 1])\n",
    "    batch_indices_bottom = tf.tile(batch_indices_bottom, [1, num_bottom_values])\n",
    "    bottom_gather_indices = tf.stack([tf.cast(batch_indices_bottom, tf.int32), tf.cast(bottom_indices, tf.int32)], axis=-1)\n",
    "    student_bottom_values = tf.gather_nd(student_flat, bottom_gather_indices)\n",
    "    euclidean_top = tf.sqrt(tf.reduce_sum(tf.square(top_values - student_top_values), axis=1))\n",
    "    euclidean_bottom = tf.sqrt(tf.reduce_sum(tf.square(bottom_values - student_bottom_values), axis=1))\n",
    "    total_euclidean_distance = tf.reduce_mean(euclidean_top + euclidean_bottom)\n",
    "    return total_euclidean_distance\n",
    "\n",
    "@tf.function\n",
    "def attention_transfer_loss_top50_euclidean_distance(teacher_saliency_map, student_saliency_map):\n",
    "    teacher_saliency_map = tf.cast(teacher_saliency_map, tf.float32)\n",
    "    student_saliency_map = tf.cast(student_saliency_map, tf.float32)    \n",
    "    batch_size = tf.shape(teacher_saliency_map)[0]\n",
    "    teacher_flat = tf.reshape(teacher_saliency_map, [batch_size, -1]) \n",
    "    student_flat = tf.reshape(student_saliency_map, [batch_size, -1])   \n",
    "    num_top_values = 20    \n",
    "    num_pixels = tf.shape(teacher_flat)[1]\n",
    "    num_top_values = tf.minimum(num_top_values, num_pixels)    \n",
    "    top_values, top_indices = tf.math.top_k(teacher_flat, k=num_top_values, sorted=True)   \n",
    "    batch_indices = tf.reshape(tf.range(batch_size), [-1, 1]) \n",
    "    batch_indices = tf.tile(batch_indices, [1, num_top_values]) \n",
    "    gather_indices = tf.stack([tf.cast(batch_indices, tf.int32), tf.cast(top_indices, tf.int32)], axis=-1) \n",
    "    student_top_values = tf.gather_nd(student_flat, gather_indices)\n",
    "    difference = top_values - student_top_values\n",
    "    squared_difference = tf.square(difference)\n",
    "    sum_squared_difference = tf.reduce_sum(squared_difference, axis=1)\n",
    "    euclidean_distance = tf.sqrt(sum_squared_difference)\n",
    "    loss = tf.reduce_mean(euclidean_distance)    \n",
    "    return loss\n",
    "\n",
    "@tf.function\n",
    "\n",
    "def attention_transfer_loss_cosine_similarity(teacher_saliency_map, student_saliency_map):\n",
    "    teacher_saliency_map = tf.cast(teacher_saliency_map, tf.float32)\n",
    "    student_saliency_map = tf.cast(student_saliency_map, tf.float32)\n",
    "    dot_product = tf.reduce_sum(teacher_saliency_map * student_saliency_map, axis=[1,2,3])\n",
    "    magnitude_teacher = tf.sqrt(tf.reduce_sum(tf.square(teacher_saliency_map), axis=[1,2,3]))\n",
    "    magnitude_student = tf.sqrt(tf.reduce_sum(tf.square(student_saliency_map), axis=[1,2,3]))\n",
    "    cosine_similarity = dot_product / (magnitude_teacher * magnitude_student + 1e-8)  # Adding epsilon for numerical stability\n",
    "    return -tf.reduce_mean(cosine_similarity)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "\n",
    "def train_step(conv_model, batch_inputs, batch_labels, teacher_saliency):\n",
    "    with tf.GradientTape() as tape:\n",
    "        student_outputs = conv_model(batch_inputs, training=True)\n",
    "        student_loss = tf.reduce_mean(\n",
    "            tf.keras.losses.categorical_crossentropy(batch_labels, student_outputs)\n",
    "        )\n",
    "        with tf.GradientTape() as tape_student:\n",
    "            tape_student.watch(batch_inputs)\n",
    "            student_outputs = conv_model(batch_inputs, training=True)\n",
    "            student_loss_inner = tf.reduce_mean(\n",
    "                tf.keras.losses.categorical_crossentropy(batch_labels, student_outputs)\n",
    "            )\n",
    "        student_grads = tape_student.gradient(student_loss_inner, batch_inputs)\n",
    "        att_loss = attention_transfer_loss_top50_euclidean_distance_normalized_student(teacher_saliency, student_grads)\n",
    "        total_loss = student_loss + att_loss\n",
    "    gradients = tape.gradient(total_loss, conv_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, conv_model.trainable_variables))\n",
    "    return total_loss, student_loss, att_loss\n",
    "\n",
    "\n",
    "EPOCHS = 50\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Starting epoch {epoch + 1}/{EPOCHS}\")\n",
    "    batch_index = 0\n",
    "    for (batch_inputs, batch_labels), teacher_saliency in train_dataset_with_saliency:\n",
    "        total_loss, student_loss, att_loss = train_step(conv_model2, batch_inputs, batch_labels, teacher_saliency)\n",
    "\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f\"Batch {batch_index}: Total Loss: {total_loss.numpy()}, \"\n",
    "                  f\"Student Loss: {student_loss.numpy()}, Attention Loss: {att_loss.numpy()}\")\n",
    "        batch_index += 1\n",
    "    test_loss = 0.0\n",
    "    test_accuracy = 0.0\n",
    "    num_batches = 0\n",
    "    for test_inputs, test_labels in test_dataset:\n",
    "        test_outputs = conv_model2(test_inputs, training=False)\n",
    "        loss = tf.reduce_mean(tf.keras.losses.categorical_crossentropy(test_labels, test_outputs))\n",
    "        accuracy = tf.reduce_mean(\n",
    "            tf.keras.metrics.categorical_accuracy(test_labels, test_outputs)\n",
    "        )\n",
    "        test_loss += loss\n",
    "        test_accuracy += accuracy\n",
    "        num_batches += 1\n",
    "    test_loss /= num_batches\n",
    "    test_accuracy /= num_batches\n",
    "    print(f'Epoch {epoch + 1}, Test Loss: {test_loss.numpy():.4f}, Test Accuracy: {test_accuracy.numpy():.2%}')\n",
    "\n",
    "    '''if test_accuracy.numpy() > 0.85:\n",
    "        print(\"Reached target accuracy. Stopping training.\")\n",
    "        break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc6e8278-3661-4f73-9ab5-a60c7fb6190a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention_transfer_loss_top50_euclidean_distance_normalized_student(teacher_saliency_map, student_saliency_map, num_top_values=2):\n",
    "    teacher_saliency_map = tf.cast(teacher_saliency_map, tf.float32)\n",
    "    student_saliency_map = tf.cast(student_saliency_map, tf.float32)\n",
    "    batch_size = tf.shape(teacher_saliency_map)[0]\n",
    "    teacher_flat = tf.reshape(teacher_saliency_map, [batch_size, -1]) \n",
    "    student_flat = tf.reshape(student_saliency_map, [batch_size, -1]) \n",
    "    student_mean = tf.reduce_mean(student_flat, axis=1, keepdims=True)  \n",
    "    student_centered = student_flat - student_mean  \n",
    "    epsilon = 1e-8\n",
    "    student_norm = tf.norm(student_centered, axis=1, keepdims=True) + epsilon  \n",
    "    student_normalized = student_centered / student_norm  \n",
    "    num_pixels = tf.shape(teacher_flat)[1]\n",
    "    num_top_values = tf.minimum(num_top_values, num_pixels) \n",
    "    top_values, top_indices = tf.math.top_k(teacher_flat, k=num_top_values, sorted=True)  \n",
    "    batch_indices = tf.reshape(tf.range(batch_size), [-1, 1])  \n",
    "    batch_indices = tf.tile(batch_indices, [1, num_top_values])  \n",
    "    gather_indices = tf.stack([tf.cast(batch_indices, tf.int32), tf.cast(top_indices, tf.int32)], axis=-1)  \n",
    "    student_top_values = tf.gather_nd(student_normalized, gather_indices)  \n",
    "    difference = tf.cast(top_values, tf.float32) - student_top_values  \n",
    "    squared_difference = tf.square(difference)\n",
    "    sum_squared_difference = tf.reduce_sum(squared_difference, axis=1)  \n",
    "    euclidean_distance = tf.sqrt(sum_squared_difference) \n",
    "    loss = tf.reduce_mean(euclidean_distance)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae45ea67-6c90-4887-bdfb-c192209f50da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
